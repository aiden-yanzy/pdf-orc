"""
Standalone PDF OCR â†’ Markdown pipeline.

This module is extracted from the zhihu_short_novel project and can be used
independently under ~/ai-lab/pdf_ocr.
"""

from __future__ import annotations

import argparse
import os
from dataclasses import dataclass
from pathlib import Path
from shutil import which
from typing import Iterable, TypedDict

import numpy as np
from dotenv import load_dotenv
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langgraph.graph import StateGraph, START, END

from pdf_ocr.extractors import PDFExtractionOptions, extract_pdf_to_text

try:
    from langchain_huggingface import HuggingFaceEmbeddings
except ImportError:  # pragma: no cover - fallback for older installations
    try:
        from langchain_community.embeddings import HuggingFaceEmbeddings  # type: ignore

        print(
            "âš ï¸ æ£€æµ‹åˆ°æ—§ç‰ˆ langchain-community çš„ HuggingFaceEmbeddingsï¼Œ"
            "å»ºè®® `pip install -U langchain-huggingface` å¹¶æ›´æ–°é…ç½®ä»¥æ¶ˆé™¤å¼ƒç”¨è­¦å‘Šã€‚"
        )
    except ImportError:
        HuggingFaceEmbeddings = None  # type: ignore

if "TOKENIZERS_PARALLELISM" not in os.environ:
    os.environ["TOKENIZERS_PARALLELISM"] = "false"


DEFAULT_INPUT_DIR = Path("inputs")
DEFAULT_OUTPUT_DIR = Path("outputs") / "pdf_markdown"


class PDFProcessingState(TypedDict, total=False):
    """LangGraph çŠ¶æ€ç»“æž„ã€‚"""

    pdf_path: str
    assets_dir: str
    page_texts: list[str]
    combined_text: str
    chunks: list[str]
    chunk_embeddings: list[list[float]]
    embed_available: bool
    refined_chunks: list[str]
    final_markdown: str
    media_assets: list[dict]


@dataclass
class PDFProcessingConfig:
    """è¿è¡Œé…ç½®å‚æ•°ã€‚"""

    input_dir: Path = DEFAULT_INPUT_DIR
    output_dir: Path = DEFAULT_OUTPUT_DIR
    overwrite: bool = False
    ocr_langs: str = os.getenv("OCR_LANGS", "chi_sim+eng")
    ocr_min_text_threshold: int = 40  # é¡µé¢æ–‡å­—ä¸è¶³æ—¶è§¦å‘ OCR
    page_dpi: int = 300
    max_chunk_chars: int = 4000
    chunk_overlap: int = 200
    rag_top_k: int = 3
    similarity_threshold: float = 0.35
    embedding_backend: str = os.getenv("EMBEDDING_BACKEND", "local")
    local_embed_model: str = os.getenv("LOCAL_EMBED_MODEL", "sentence-transformers/all-MiniLM-L6-v2")
    local_embed_device: str = os.getenv("LOCAL_EMBED_DEVICE", "cpu")
    extract_images: bool = os.getenv("EXTRACT_IMAGES", "true").lower() == "true"
    enable_formula_detection: bool = os.getenv("ENABLE_FORMULA_DETECTION", "true").lower() == "true"


class PDFMarkdownConverter:
    """å°† PDF è½¬æ¢ä¸º Markdownï¼Œå¹¶é€šè¿‡ LLM ä¿®æ­£æ–‡æœ¬ã€‚"""

    def __init__(self, config: PDFProcessingConfig):
        load_dotenv()

        self.config = config
        self.config.input_dir = config.input_dir.expanduser()
        self.config.output_dir = config.output_dir.expanduser()
        self.verbose = os.getenv("VERBOSE", "True").lower() == "true"

        self._ensure_directories()

        self._tesseract_available = which("tesseract") is not None
        if not self._tesseract_available:
            print("âš ï¸ æœªæ£€æµ‹åˆ° tesseract å¯æ‰§è¡Œæ–‡ä»¶ï¼Œæ— æ³•è¿›è¡Œ OCRï¼Œå°†ä»…å°è¯•ç›´æŽ¥æå–æ–‡æœ¬ã€‚")

        self.llm = self._create_llm()
        self.embedder = self._create_embedder()
        self.workflow = self._build_workflow()

    def _ensure_directories(self) -> None:
        if not self.config.input_dir.exists():
            raise FileNotFoundError(f"è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {self.config.input_dir}")
        self.config.output_dir.mkdir(parents=True, exist_ok=True)

    def _build_extraction_options(self) -> PDFExtractionOptions:
        return PDFExtractionOptions(
            ocr_langs=self.config.ocr_langs,
            ocr_min_text_threshold=self.config.ocr_min_text_threshold,
            page_dpi=self.config.page_dpi,
            extract_images=self.config.extract_images,
            enable_formula_detection=self.config.enable_formula_detection,
            output_dir=self.config.output_dir,
            tesseract_available=self._tesseract_available,
        )

    def _create_llm(self) -> ChatOpenAI:
        api_key = os.getenv("OPENAI_API_KEY", "")
        base_url = os.getenv("OPENAI_BASE_URL", "http://localhost:3000/v1")
        model_name = os.getenv("OPENAI_MODEL", "claude-3-7-sonnet-20250219")
        temperature = float(os.getenv("OPENAI_TEMPERATURE", "0.7"))
        if not api_key and base_url:
            print("âš ï¸ æœªè®¾ç½® OPENAI_API_KEYï¼Œå°†å°è¯•ä½¿ç”¨ base_url ä»£ç†ã€‚")

        return ChatOpenAI(
            model=model_name,
            base_url=base_url,
            api_key=api_key or None,
            temperature=temperature,
        )

    def _create_embedder(self):
        backend = (self.config.embedding_backend or "openai").lower()

        if backend in {"none", "disabled", "off"}:
            print("â„¹ï¸ å·²ç¦ç”¨å‘é‡åµŒå…¥ï¼ŒRAG åŠŸèƒ½å…³é—­ã€‚")
            return None

        if backend == "local":
            if HuggingFaceEmbeddings is None:
                print("âš ï¸ ç¼ºå°‘ langchain-huggingface ä¾èµ–ï¼Œæ— æ³•åŠ è½½æœ¬åœ°åµŒå…¥æ¨¡åž‹ï¼Œå°†è·³è¿‡ RAGã€‚")
                return None

            model_name = self.config.local_embed_model
            device = self.config.local_embed_device
            try:
                embedder = HuggingFaceEmbeddings(
                    model_name=model_name,
                    model_kwargs={"device": device},
                    encode_kwargs={"normalize_embeddings": True},
                )
                if self.verbose:
                    print(f"ðŸ”§ Local Embedding Model: {model_name} (device={device})")
                return embedder
            except Exception as exc:  # pragma: no cover
                print(f"âš ï¸ åˆå§‹åŒ–æœ¬åœ°åµŒå…¥æ¨¡åž‹å¤±è´¥ï¼Œå°†è·³è¿‡ RAG ç›¸ä¼¼åº¦æ£€ç´¢: {exc}")
                return None

        api_key = os.getenv("OPENAI_API_KEY", "")
        embed_model = os.getenv("OPENAI_EMBED_MODEL", "text-embedding-3-small")
        embed_base_url = os.getenv("OPENAI_EMBED_BASE_URL") or os.getenv("OPENAI_BASE_URL")

        if not api_key and not embed_base_url:
            print("âš ï¸ æœªæ£€æµ‹åˆ°åµŒå…¥æ¨¡åž‹é…ç½®ï¼Œå°†è·³è¿‡ RAG ç›¸ä¼¼åº¦æ£€ç´¢ã€‚")
            return None

        try:
            embedder = OpenAIEmbeddings(
                model=embed_model,
                openai_api_key=api_key or None,
                openai_api_base=embed_base_url,
            )
            if self.verbose:
                print("ðŸ”§ Embedding Model:", embed_model)
            return embedder
        except Exception as exc:  # pragma: no cover
            print(f"âš ï¸ åˆå§‹åŒ–åµŒå…¥æ¨¡åž‹å¤±è´¥ï¼Œå°†è·³è¿‡ RAG ç›¸ä¼¼åº¦æ£€ç´¢: {exc}")
            return None

    def _build_workflow(self):
        graph = StateGraph(PDFProcessingState)
        graph.add_node("extract_text", self._node_extract_text)
        graph.add_node("chunk_text", self._node_chunk_text)
        graph.add_node("embed_chunks", self._node_embed_chunks)
        graph.add_node("refine_chunks", self._node_refine_chunks)
        graph.add_node("assemble_markdown", self._node_assemble_markdown)

        graph.add_edge(START, "extract_text")
        graph.add_edge("extract_text", "chunk_text")
        graph.add_edge("chunk_text", "embed_chunks")
        graph.add_edge("embed_chunks", "refine_chunks")
        graph.add_edge("refine_chunks", "assemble_markdown")
        graph.add_edge("assemble_markdown", END)

        return graph.compile()

    def _node_extract_text(self, state: PDFProcessingState) -> PDFProcessingState:
        pdf_path = Path(state["pdf_path"])
        assets_dir = Path(state.get("assets_dir", self.config.output_dir / f"{pdf_path.stem}_assets"))
        page_texts, combined_text, media_assets = self._extract_pdf_content(pdf_path, assets_dir)

        updated = dict(state)
        updated["page_texts"] = page_texts
        updated["combined_text"] = combined_text
        updated["media_assets"] = media_assets
        print(f"ðŸ“š å·²æå– {len(page_texts)} é¡µæ–‡æœ¬ï¼Œæ€»é•¿åº¦ {len(combined_text)} å­—ç¬¦ã€‚")
        return updated

    def _node_chunk_text(self, state: PDFProcessingState) -> PDFProcessingState:
        combined_text = state.get("combined_text", "")
        chunks = self._split_into_chunks(combined_text)
        updated = dict(state)
        updated["chunks"] = chunks
        avg = (sum(len(c) for c in chunks) // len(chunks)) if chunks else 0
        print(f"ðŸ§© æ–‡æœ¬æ‹†åˆ†ä¸º {len(chunks)} æ®µï¼Œå¹³å‡é•¿åº¦çº¦ {avg} å­—ç¬¦ã€‚")
        return updated

    def _node_embed_chunks(self, state: PDFProcessingState) -> PDFProcessingState:
        chunks = state.get("chunks", [])
        updated = dict(state)
        if not chunks:
            updated["chunk_embeddings"] = []
            updated["embed_available"] = False
            print("âš ï¸ æ— æ–‡æœ¬åˆ†æ®µï¼Œå¯è·³è¿‡åµŒå…¥è®¡ç®—ã€‚")
            return updated

        if not self.embedder:
            updated["chunk_embeddings"] = []
            updated["embed_available"] = False
            print("âš ï¸ æœªé…ç½®åµŒå…¥æ¨¡åž‹ï¼Œè·³è¿‡ç›¸ä¼¼åº¦æ£€ç´¢ã€‚")
            return updated

        try:
            embeddings = self.embedder.embed_documents(chunks)  # type: ignore[union-attr]
            updated["chunk_embeddings"] = embeddings
            updated["embed_available"] = True
            print(f"ðŸ“Š å·²ç”Ÿæˆ {len(embeddings)} ä¸ªå‘é‡åµŒå…¥ï¼Œç”¨äºŽ RAG æ£€ç´¢ã€‚")
        except Exception as exc:  # pragma: no cover
            updated["chunk_embeddings"] = []
            updated["embed_available"] = False
            print(f"âš ï¸ å‘é‡åµŒå…¥ç”Ÿæˆå¤±è´¥ï¼Œå°†é€€åŒ–ä¸ºé¡ºåºä¸Šä¸‹æ–‡ï¼š{exc}")
            self.embedder = None
        return updated

    def _node_refine_chunks(self, state: PDFProcessingState) -> PDFProcessingState:
        chunks = state.get("chunks", [])
        if not chunks:
            raise ValueError("æœªèŽ·å–åˆ°ä»»ä½•æ–‡æœ¬åˆ†æ®µï¼Œæ— æ³•è¿›è¡Œ LLM ä¿®å¤ã€‚")

        embeddings = state.get("chunk_embeddings") or []
        embed_available = state.get("embed_available", False) and len(embeddings) == len(chunks)
        vector_matrix = np.array(embeddings) if embed_available else None

        results: list[str] = []
        for idx, chunk in enumerate(chunks, start=0):
            print(f"ðŸ¤– æ­£åœ¨ä¿®å¤æ®µ {idx + 1}/{len(chunks)}ï¼Œé•¿åº¦ {len(chunk)} å­—ç¬¦ã€‚")
            context_indices: list[int] = []
            if idx > 0:
                context_indices.append(idx - 1)

            if embed_available and vector_matrix is not None and vector_matrix.size > 0:
                similar_indices = self._retrieve_similar_indices(vector_matrix, idx)
                context_indices.extend(similar_indices)

            context_indices = [i for i in dict.fromkeys(context_indices) if i != idx]
            if context_indices:
                print(f"   â”‚  ä½¿ç”¨ä¸Šä¸‹æ–‡æ®µç´¢å¼•: {context_indices}")
            else:
                print("   â”‚  æœªæ£€ç´¢åˆ°é¢å¤–ä¸Šä¸‹æ–‡ï¼Œä½¿ç”¨å½“å‰æ®µè½ç‹¬ç«‹ä¿®å¤ã€‚")

            context_snippets = [chunks[i] for i in context_indices]
            context_text = "\n\n---\n\n".join(context_snippets) if context_snippets else "æ— "

            system_prompt = (
                "ä½ æ˜¯ä¸€åä¸“ä¸šçš„æ–‡æœ¬ç¼–è¾‘ï¼Œéœ€è¦å°† OCR ç»“æžœæ•´ç†æˆç»“æž„åŒ–çš„ Markdown æ–‡æ¡£ã€‚"
                "è¯·çº æ­£æ˜Žæ˜¾çš„è¯†åˆ«é”™è¯¯ï¼Œä¿ç•™åŽŸæ–‡è¯­æ°”ï¼Œåˆå¹¶æ–­è£‚çš„å¥å­ï¼Œå¹¶åœ¨å¿…è¦æ—¶åŠ å…¥å°èŠ‚æ ‡é¢˜ã€‚"
                "å¦‚æžœæ£€æµ‹åˆ°é”™åˆ«å­—ã€ä¹±ç æˆ–è¯­å¥ä¸é€šé¡ºï¼Œè¯·åœ¨åˆç†èŒƒå›´å†…ä¿®æ­£ã€‚"
                "å¯¹æä¾›çš„ä¸Šä¸‹æ–‡è¿›è¡Œé€‚åº¦å‚ç…§ï¼Œä½†ä¸è¦é‡å¤ä¸Šä¸‹æ–‡å†…å®¹ã€‚"
                "è¾“å‡ºåº”åªåŒ…å«ä¿®æ­£åŽçš„æ­£æ–‡ï¼Œä¸è¦åŠ å…¥ä¿®å¤è¯´æ˜Žã€æç¤ºè¯­æˆ–ä»»ä½•ä¸Žæ­£æ–‡æ— å…³çš„è§£é‡Šã€‚"
                "è‹¥æ–‡æœ¬ä¸­å·²å­˜åœ¨å›¾ç‰‡æˆ–å…¬å¼å ä½ç¬¦ï¼Œè¯·åŽŸæ ·ä¿ç•™ï¼Œæ— éœ€é¢å¤–è¯´æ˜Žã€‚"
            )
            user_prompt = (
                f"æ–‡ä»¶å: {Path(state['pdf_path']).name}\n"
                f"å½“å‰æ®µè½åºå·: {idx + 1}/{len(chunks)}\n"
                "ä»¥ä¸‹ä¸Šä¸‹æ–‡ä»…ä¾›ç†è§£ï¼Œè¯·å‹¿åœ¨è¾“å‡ºä¸­é‡å¤ï¼š\n"
                "```text\n"
                f"{context_text}\n"
                "```\n\n"
                "ä»¥ä¸‹æ˜¯éœ€è¦ä¿®å¤çš„ OCR æ–‡æœ¬ï¼Œè¯·è¾“å‡º Markdownï¼š\n"
                "```text\n"
                f"{chunk}\n"
                "```"
            )

            response = self.llm.invoke(
                [
                    SystemMessage(content=system_prompt),
                    HumanMessage(content=user_prompt),
                ]
            )

            content = getattr(response, "content", "")
            if isinstance(content, list):
                content = "".join(
                    chunk_piece.get("text", "")
                    for chunk_piece in content
                    if isinstance(chunk_piece, dict)
                )
            if not content.strip():
                raise RuntimeError("LLM è¿”å›žå†…å®¹ä¸ºç©ºã€‚")

            results.append(content.strip())

        updated = dict(state)
        updated["refined_chunks"] = results
        return updated

    def _node_assemble_markdown(self, state: PDFProcessingState) -> PDFProcessingState:
        refined = state.get("refined_chunks") or []
        if not refined:
            refined = state.get("chunks", [])
        final_markdown = "\n\n".join(refined).strip()
        print(f"ðŸ§¾ Markdown èšåˆå®Œæˆï¼Œæœ€ç»ˆé•¿åº¦ {len(final_markdown)} å­—ç¬¦ã€‚")
        updated = dict(state)
        updated["final_markdown"] = final_markdown
        return updated

    def process_all(self) -> list[Path]:
        pdf_files = sorted(self.config.input_dir.glob("*.pdf"))
        if not pdf_files:
            print("ðŸ“‚ æœªåœ¨è¾“å…¥ç›®å½•ä¸­æ‰¾åˆ° PDF æ–‡ä»¶ã€‚")
            return []

        print(f"ðŸ“‘ å…±æ£€æµ‹åˆ° {len(pdf_files)} ä¸ª PDFï¼Œå°†é€ä¸€å¤„ç†ã€‚")
        generated_files: list[Path] = []
        for pdf_path in pdf_files:
            try:
                output_path = self._process_single(pdf_path)
                generated_files.append(output_path)
                print(f"âœ… å·²ç”Ÿæˆ: {output_path}")
            except Exception as exc:  # pragma: no cover
                print(f"âŒ å¤„ç† {pdf_path.name} æ—¶å¤±è´¥: {exc}")
        return generated_files

    def _process_single(self, pdf_path: Path) -> Path:
        print(f"ðŸ“„ å¼€å§‹å¤„ç†: {pdf_path.name}")
        output_path = self.config.output_dir / (pdf_path.stem + ".md")
        assets_dir = self.config.output_dir / f"{pdf_path.stem}_assets"
        if self.config.extract_images:
            assets_dir.mkdir(parents=True, exist_ok=True)
        if output_path.exists() and not self.config.overwrite:
            print(f"â­ï¸ è·³è¿‡å·²æœ‰æ–‡ä»¶: {output_path}")
            return output_path

        final_state = self.workflow.invoke(
            {"pdf_path": str(pdf_path), "assets_dir": str(assets_dir)},
            config={"configurable": {"thread_id": f"pdf-{pdf_path.stem}"}},
        )

        markdown_text = (final_state.get("final_markdown") or "").strip()
        if not markdown_text:
            raise ValueError("LLM ä¿®å¤åŽå†…å®¹ä¸ºç©ºï¼Œå¯èƒ½æ˜¯ä¸Šæ¸¸æ­¥éª¤å¤±è´¥ã€‚")

        output_path.write_text(markdown_text, encoding="utf-8")
        return output_path

    def _extract_pdf_content(self, pdf_path: Path, assets_dir: Path) -> tuple[list[str], str, list[dict]]:
        options = self._build_extraction_options()
        logger = print
        assets_target: Path | None = assets_dir if self.config.extract_images else None
        result = extract_pdf_to_text(
            pdf_path,
            assets_dir=assets_target,
            options=options,
            logger=logger,
        )
        return result.page_texts, result.combined_text, result.media_assets

    def _split_into_chunks(self, text: str) -> list[str]:
        max_chars = max(1000, self.config.max_chunk_chars)
        overlap = max(0, min(self.config.chunk_overlap, max_chars // 2))
        cleaned = text.strip()
        if len(cleaned) <= max_chars:
            return [cleaned]

        chunks: list[str] = []
        start = 0
        text_length = len(cleaned)
        while start < text_length:
            end = min(text_length, start + max_chars)
            chunk = cleaned[start:end]
            chunks.append(chunk.strip())
            if end == text_length:
                break
            start = max(0, end - overlap)

        return [chunk for chunk in chunks if chunk]

    def _retrieve_similar_indices(self, matrix: np.ndarray, target_idx: int) -> list[int]:
        if len(matrix) <= 1:
            return []

        top_k = max(0, self.config.rag_top_k)
        if top_k == 0:
            return []

        target_vec = matrix[target_idx]
        target_norm = np.linalg.norm(target_vec)
        if target_norm == 0:
            return []

        norms = np.linalg.norm(matrix, axis=1) + 1e-10
        similarities = (matrix @ target_vec) / (norms * target_norm + 1e-10)
        similarities[target_idx] = -1.0

        sorted_indices = np.argsort(similarities)[::-1]
        selected: list[int] = []
        for idx in sorted_indices:
            if len(selected) >= top_k:
                break
            score = similarities[idx]
            if score < self.config.similarity_threshold:
                continue
            selected.append(int(idx))

        return selected



def build_parser() -> argparse.ArgumentParser:
    parser = argparse.ArgumentParser(description="å¯¹ inputs ç›®å½•ä¸­çš„ PDF è¿›è¡Œ OCR å¹¶ç”Ÿæˆ Markdownã€‚")
    parser.add_argument("--input_dir", type=Path, default=DEFAULT_INPUT_DIR, help="PDF è¾“å…¥ç›®å½•ã€‚")
    parser.add_argument(
        "--output_dir",
        type=Path,
        default=DEFAULT_OUTPUT_DIR,
        help="Markdown è¾“å‡ºç›®å½•ã€‚",
    )
    parser.add_argument("--overwrite", action="store_true", help="å…è®¸è¦†ç›–å·²æœ‰ Markdown æ–‡ä»¶ã€‚")
    parser.add_argument(
        "--ocr_langs",
        type=str,
        default=os.getenv("OCR_LANGS", "chi_sim+eng"),
        help="pytesseract è¯­è¨€åŒ…å‚æ•°ï¼Œä¾‹å¦‚ 'chi_sim+eng'ã€‚",
    )
    parser.add_argument(
        "--ocr_min_text_threshold",
        type=int,
        default=40,
        help="å½“é¡µé¢ç›´æŽ¥æå–çš„å­—ç¬¦æ•°ä½ŽäºŽè¯¥å€¼æ—¶è§¦å‘ OCRã€‚",
    )
    parser.add_argument("--page_dpi", type=int, default=300, help="OCR æ¸²æŸ“ä½¿ç”¨çš„ DPIã€‚")
    parser.add_argument(
        "--max_chunk_chars",
        type=int,
        default=4000,
        help="ä¼ å…¥ LLM å‰å•æ®µæœ€å¤§å­—ç¬¦æ•°ï¼Œè¶…è¿‡ä¼šæ‹†åˆ†ã€‚",
    )
    parser.add_argument(
        "--chunk_overlap",
        type=int,
        default=200,
        help="åˆ†æ®µæ—¶çš„å­—ç¬¦é‡å ï¼Œç”¨äºŽä¿æŒä¸Šä¸‹æ–‡è¿žè´¯ã€‚",
    )
    parser.add_argument(
        "--rag_top_k",
        type=int,
        default=3,
        help="RAG æ£€ç´¢æ—¶è¿”å›žçš„ç›¸ä¼¼æ®µè½æ•°é‡ã€‚",
    )
    parser.add_argument(
        "--similarity_threshold",
        type=float,
        default=0.35,
        help="å½“ç›¸ä¼¼åº¦ä½ŽäºŽè¯¥é˜ˆå€¼æ—¶å¿½ç•¥æ£€ç´¢ç»“æžœã€‚",
    )
    parser.add_argument(
        "--embedding_backend",
        type=str,
        default=os.getenv("EMBEDDING_BACKEND", "local"),
        choices=["local", "openai", "none"],
        help="å‘é‡åµŒå…¥åŽç«¯ï¼Œå¯é€‰ local/openai/noneã€‚",
    )
    parser.add_argument(
        "--local_embed_model",
        type=str,
        default=os.getenv("LOCAL_EMBED_MODEL", "sentence-transformers/all-MiniLM-L6-v2"),
        help="æœ¬åœ°åµŒå…¥æ¨¡åž‹åç§°æˆ–ç›®å½•ï¼ˆéœ€è¦æå‰ä¸‹è½½ï¼‰ã€‚",
    )
    parser.add_argument(
        "--local_embed_device",
        type=str,
        default=os.getenv("LOCAL_EMBED_DEVICE", "cpu"),
        help="æœ¬åœ°åµŒå…¥æ¨¡åž‹åŠ è½½è®¾å¤‡ï¼Œä¾‹å¦‚ cpuã€cudaã€‚",
    )
    parser.add_argument(
        "--extract_images",
        action="store_true",
        default=os.getenv("EXTRACT_IMAGES", "true").lower() == "true",
        help="å¯ç”¨å›¾ç‰‡æå–å¹¶å†™å…¥ Markdownã€‚",
    )
    parser.add_argument(
        "--no-extract_images",
        dest="extract_images",
        action="store_false",
        help="ç¦ç”¨å›¾ç‰‡æå–ã€‚",
    )
    parser.add_argument(
        "--enable_formula_detection",
        action="store_true",
        default=os.getenv("ENABLE_FORMULA_DETECTION", "true").lower() == "true",
        help="å¯ç”¨å…¬å¼æ£€æµ‹å¹¶æ’å…¥ LaTeX å ä½ç¬¦ã€‚",
    )
    parser.add_argument(
        "--disable_formula_detection",
        dest="enable_formula_detection",
        action="store_false",
        help="ç¦ç”¨å…¬å¼æ£€æµ‹ã€‚",
    )
    return parser


def run_from_cli(args: Iterable[str] | None = None) -> list[Path]:
    parser = build_parser()
    parsed = parser.parse_args(args=args)

    config = PDFProcessingConfig(
        input_dir=parsed.input_dir,
        output_dir=parsed.output_dir,
        overwrite=parsed.overwrite,
        ocr_langs=parsed.ocr_langs,
        ocr_min_text_threshold=parsed.ocr_min_text_threshold,
        page_dpi=parsed.page_dpi,
        max_chunk_chars=parsed.max_chunk_chars,
        chunk_overlap=parsed.chunk_overlap,
        rag_top_k=parsed.rag_top_k,
        similarity_threshold=parsed.similarity_threshold,
        embedding_backend=parsed.embedding_backend,
        local_embed_model=parsed.local_embed_model,
        local_embed_device=parsed.local_embed_device,
        extract_images=parsed.extract_images,
        enable_formula_detection=parsed.enable_formula_detection,
    )

    processor = PDFMarkdownConverter(config)
    return processor.process_all()


def main():
    """Console entrypoint."""
    run_from_cli()


if __name__ == "__main__":  # pragma: no cover
    main()
